![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Project Status](https://img.shields.io/badge/Project%20Status-Completed-success)
![PRs](https://img.shields.io/badge/PRs-welcome-brightgreen)

# ğŸ§  Text Classification using DistilBERT

## ğŸ“Œ Overview  
This project focuses on **text classification** using the **DistilBERT** model, a lightweight and efficient version of BERT developed by Hugging Face. The notebook walks through the entire pipeline of natural language processing â€” from loading and preprocessing a text dataset to fine-tuning the transformer model and evaluating its performance. The aim is to build a robust, high-performing classifier that can generalize well to unseen text data using minimal resources and training time.

---

ğŸš€ Live Demo
Experience the power of DistilBERT live! Click the link below to test the sentiment analysis tool in real-time using Streamlit:

ğŸ”— [Try Sentivibe ğŸ’¬](https://sentivibe.streamlit.app/)

---
ğŸ¥ Project Walkthrough
Check out the full explanation and walkthrough of the app, including development and usage:

â–¶ï¸ [Watch on YouTube](https://youtu.be/DlBC7CpucT8?si=FX40yK66UWbcFZme)

## ğŸ¯ Objectives  
- Load and prepare text data for classification tasks  
- Tokenize and encode text using **DistilBERT tokenizer**  
- Fine-tune the **`distilbert-base-uncased`** model on the dataset  
- Evaluate model performance using key NLP metrics  
- Predict outcomes on new, custom text samples  

---

## ğŸ”„ Project Workflow  

### 1. ğŸ“‚ Data Preparation  
- Load a labeled text dataset (e.g., binary/multiclass)  
- Encode categorical labels into numerical format  
- Split dataset into **training** and **testing** sets  

### 2. ğŸ”  Tokenization  
- Use Hugging Face's **DistilBERT tokenizer**  
- Convert text into token IDs and attention masks  
- Ensure proper padding and truncation  

### 3. ğŸ§  Model Implementation - DistilBERT  
- Use `transformers` library to load **`distilbert-base-uncased`**  
- Add a classification head on top (e.g., linear layer)  
- Fine-tune the model using **PyTorch** or **Trainer API**  

### 4. ğŸ“Š Evaluation  
- Compute metrics including:  
  - âœ… **Accuracy**  
  - âœ… **Precision & Recall**  
  - âœ… **F1-Score**  
  - âœ… **Confusion Matrix**  
- Visualize results for deeper insights  

### 5. ğŸ”® Inference  
- Pass custom text inputs to the trained model  
- Return predicted labels with confidence scores  

---

## ğŸ§ª Libraries & Tools  
- ğŸ¤— `transformers` â€“ Hugging Face model & tokenizer  
- ğŸ“Š `sklearn` â€“ Evaluation metrics  
- ğŸ§® `pandas`, `numpy` â€“ Data handling  
- ğŸ”¥ `torch` â€“ Model training (or optionally, TensorFlow)

---

## âœï¸ Author

**Arpita Mishra**  
B.Tech CSE, [C.V Raman Global University]  
*Passionate about NLP, AI, and deep learning.*


